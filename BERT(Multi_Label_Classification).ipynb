{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/B0Z/knLr6TEbwAxacUFa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuanRuLai/Python-Deep-Learning/blob/main/BERT(Multi_Label_Classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "U5G6W9Ta5xrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "-othZhNn7Ppy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9zFEx-53Xc_",
        "outputId": "35103f7d-340b-4d55-c995-29e4c6fa7bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['北师教育学，你我一起努力，让胜利酣畅淋漓。', '考博英语词汇', '出售人大新闻学院2015年考研权威资料', '【脑科院 郭桃梅课题组】科研助理招聘', '管理学院的同学帮帮忙呐～']\n",
            "['【字节跳动内推】校招岗位全面开放，帮查进度！', '招聘兼职/ 笔试考务 /200-300 每人', '国企出版社招聘坐班兼职生', '【在线早教】教研实习生招聘', '【兼职】心理学公众号寻兼职写手']\n"
          ]
        }
      ],
      "source": [
        "academy_titles = []\n",
        "job_titles = []\n",
        "\n",
        "with open(\"academy_titles.txt\", \"r\", encoding= \"utf-8\") as f:\n",
        "    for l in f:\n",
        "      academy_titles.append(l.strip()) # remove spaces of head and tail\n",
        "\n",
        "with open(\"job_titles.txt\", \"r\", encoding= \"utf-8\") as f:\n",
        "    for l in f:\n",
        "      job_titles.append(l.strip()) # remove spaces of head and tail\n",
        "\n",
        "print(academy_titles[:5])\n",
        "print(job_titles[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build dataset & Split independent variables and dependent variable"
      ],
      "metadata": {
        "id": "Grup99XwVpFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "\n",
        "for title in academy_titles:\n",
        "    all_data.append([title, 0])\n",
        "\n",
        "for l in job_titles:\n",
        "    all_data.append([title, 1])\n",
        "\n",
        "print(all_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZT3t0dZVuup",
        "outputId": "5d176e05-1359-4be2-be41-c48bf7cf1ba1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['北师教育学，你我一起努力，让胜利酣畅淋漓。', 0], ['考博英语词汇', 0], ['出售人大新闻学院2015年考研权威资料', 0], ['【脑科院 郭桃梅课题组】科研助理招聘', 0], ['管理学院的同学帮帮忙呐～', 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training set and testing set(preliminary)"
      ],
      "metadata": {
        "id": "Zk4WiSqcZOPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm1MoS1fZPNH",
        "outputId": "740a93ff-c683-4afc-8afd-26c5181c4ac3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5686\n",
            "1422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary library"
      ],
      "metadata": {
        "id": "UvmcT_68FvzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification"
      ],
      "metadata": {
        "id": "OYgr0QMhF0I5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network processing"
      ],
      "metadata": {
        "id": "vgU0PiPKH9Qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check if there is GPU to use"
      ],
      "metadata": {
        "id": "rNhvchaHNLmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU available, using CPU instead.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji7GQlpbNNMK",
        "outputId": "e80fc6d8-6c31-4093-d28d-083b0ad94ca0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom dataset for BERT tokenization"
      ],
      "metadata": {
        "id": "zHY7_HeHvInp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, examples):\n",
        "    self.examples = examples\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    example = self.examples[index]\n",
        "    title = example[0]\n",
        "    label = example[1]\n",
        "\n",
        "    # convert title into a format suitable for input to a model\n",
        "    r = tokenizer.encode_plus(\n",
        "        title,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    return title, label, index"
      ],
      "metadata": {
        "id": "ECIG5Ggruf87"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define collate function to handle variable-length sequences"
      ],
      "metadata": {
        "id": "Y4I8yLGuyt12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  r = tokenizer([b[0] for b in batch], padding=True) #  ensure that all sequences in the batch are padded to the length of the longest sequence in the batch\n",
        "  input_ids = torch.LongTensor(r[\"input_ids\"]) # token ids of each title\n",
        "  attention_mask = torch.LongTensor(r[\"attention_mask\"]) # identify the token is actual data(1) or padded value(0)\n",
        "  label = torch.LongTensor([b[1] for b in batch])\n",
        "  indices = [b[2] for b in batch]\n",
        "\n",
        "  return input_ids, attention_mask, label, indices"
      ],
      "metadata": {
        "id": "38lvPPNvyurX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set hyperparameters"
      ],
      "metadata": {
        "id": "x8py5KV38tBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_train_epochs = 5\n",
        "warmup_proportion = 0.05 # the proportion of learning rate growing from slow to fast\n",
        "gradient_accumulation_steps = 4 # number of gradient steps need to accumulate before updating weights\n",
        "batch_size = 8\n",
        "data_workers = 2 # number of subprocesses to use for loading data\n",
        "\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01\n",
        "max_grad_norm = 1\n",
        "cur_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "metadata": {
        "id": "ko2g6dUs8tv6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training set and testing set(after tokenization)"
      ],
      "metadata": {
        "id": "U8V6VFqG3MdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MyDataset(train_data)\n",
        "test_data = MyDataset(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=data_workers, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=data_workers, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "lyqeusk_3Nrc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "NkV8JMoAH-7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-chinese\")\n",
        "model.to(device)\n",
        "\n",
        "t_total = len(train_loader) // gradient_accumulation_steps * max_train_epochs + 1 # total number of training steps(+1 to ensure the last step not being ignored)\n",
        "num_warmup_steps = int(t_total * warmup_proportion) # number of warmup steps\n",
        "print(\"warmup steps : %d\" % num_warmup_steps)\n",
        "\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"] # specify parameters which aren't fit for weight decaying\n",
        "param_optimizer = list(model.named_parameters()) # get all parameters\n",
        "optimizer_grouped_parameters = [\n",
        "    {\"params\":[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": weight_decay},\n",
        "    {\"params\":[p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=False)\n",
        "\n",
        "# define learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)"
      ],
      "metadata": {
        "id": "3agEZNwEIAiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ef1052-29e0-4370-ab61-8387f0196e24"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warmup steps : 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training & evaluation"
      ],
      "metadata": {
        "id": "9mqQtTuPau52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(max_train_epochs):\n",
        "  b_time = time.time() # start time\n",
        "  model.train() # weights can be modified\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for step, batch in enumerate(tqdm(train_loader)):\n",
        "    input_ids, attention_mask, label = (b.to(device) for b in batch[:-1]) # ignore the last element \"indices\"\n",
        "    optimizer.zero_grad() # return zero of every previous batch\n",
        "\n",
        "    loss = model(input_ids, attention_mask=attention_mask, labels=label)[0]\n",
        "    logits = model(input_ids, attention_mask=attention_mask, labels=label)[1]\n",
        "    loss.backward() # calculate gradient(min loss weights)\n",
        "\n",
        "    if (step + 1) % gradient_accumulation_steps == 0: # check if we achieve the accumulative steps\n",
        "      optimizer.step() # update weights\n",
        "      scheduler.step() # update learning rate\n",
        "\n",
        "    _, predicted = torch.max(logits.data, 1) # get the index of max value in each row of axis 1\n",
        "    total += label.size(0) # get the number of samples\n",
        "    correct += (predicted == label.squeeze()).sum().item()\n",
        "\n",
        "\n",
        "  accuracy = correct / total\n",
        "  print(f\"Epoch: {epoch} | Loss: {loss:.4f} | Accuracy: {accuracy:.4f} | Time: {(time.time() - b_time) / 60:.2f} min\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-YQdIqXyAhf",
        "outputId": "125ee62f-72ce-4235-8776-f73057b544a6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 711/711 [00:43<00:00, 16.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.0088 | Accuracy: 0.9889 | Time: 0.72 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 711/711 [00:53<00:00, 13.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Loss: 0.0240 | Accuracy: 0.9889 | Time: 0.89 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 711/711 [00:54<00:00, 12.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 | Loss: 0.5767 | Accuracy: 0.9889 | Time: 0.91 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 711/711 [00:43<00:00, 16.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 | Loss: 0.0216 | Accuracy: 0.9889 | Time: 0.72 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 711/711 [00:43<00:00, 16.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 | Loss: 0.0141 | Accuracy: 0.9889 | Time: 0.72 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test evaluation"
      ],
      "metadata": {
        "id": "58EgChOa0Miy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # weights cannot be modified(frozen)\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad(): # close the gradient calculation mechanism\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for step, batch in enumerate(tqdm(test_loader)):\n",
        "    input_ids, attention_mask, label = (b.to(device) for b in batch[:-1])\n",
        "\n",
        "    logits = model(input_ids, attention_mask=attention_mask, labels=label)[1]\n",
        "\n",
        "    _, predicted = torch.max(logits.data, 1)\n",
        "    total += label.size(0)\n",
        "    correct += (predicted == label.squeeze()).sum().item()\n",
        "\n",
        "    y_true.extend(label.squeeze().cpu().numpy())\n",
        "    y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "  accuracy = correct / total\n",
        "  print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYKN4tPV0NgH",
        "outputId": "a0763cc3-dc6d-45e1-847a-5eb67adbf6d5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 178/178 [00:03<00:00, 45.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer prediction"
      ],
      "metadata": {
        "id": "qCf3lRbE0WQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    \"Y_true\": y_true,\n",
        "    \"Y_pred\": y_pred\n",
        "})\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crXbcg_c0YBJ",
        "outputId": "ad0a9660-ce24-43ef-cd08-6f70407a876f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Y_true  Y_pred\n",
            "0          1       1\n",
            "1          1       1\n",
            "2          1       1\n",
            "3          1       1\n",
            "4          1       1\n",
            "...      ...     ...\n",
            "1417       1       1\n",
            "1418       0       0\n",
            "1419       1       1\n",
            "1420       0       0\n",
            "1421       0       0\n",
            "\n",
            "[1422 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}